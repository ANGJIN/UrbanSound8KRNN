{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UrbanSound8K_Classification_RNN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ANGJIN/UrbanSound8KRNN/blob/master/UrbanSound8K_Classification_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOPXlbWOAAIN",
        "colab_type": "text"
      },
      "source": [
        "My UrbanSound8K data is in google drive.  \n",
        "So, mount google drive first"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-eXN8cRBBIg",
        "colab_type": "code",
        "outputId": "e97b518e-18d1-444a-acdd-74c40eb78182",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vp_hPYbKdH0S",
        "colab_type": "text"
      },
      "source": [
        "Change present working directory to urban sound classification directory  \n",
        "which is in mounted Google drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGXyNkbJBqdx",
        "colab_type": "code",
        "outputId": "30382375-499e-4a67-f58f-a9b071d10127",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd 'drive/My Drive/urban sound classification'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/urban sound classification\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puhZ8q96dhSn",
        "colab_type": "text"
      },
      "source": [
        "Import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sINrAeP7Fw3l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "771b9dad-93bc-46ed-b1b2-69938034c7c3"
      },
      "source": [
        "import glob\n",
        "import os\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "from IPython.display import SVG\n",
        "import keras\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, TimeDistributed, Activation\n",
        "from keras.layers import Dropout, Dense, Flatten, BatchNormalization"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl56aaTJd4_7",
        "colab_type": "text"
      },
      "source": [
        "Below, there are some functions to load and pre-process data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB5WKi1lwOCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def windows(data, window_size):\n",
        "    start = 0\n",
        "    while start < len(data):\n",
        "        yield int(start), int(start + window_size)\n",
        "        start += (window_size / 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqPDritOeG0x",
        "colab_type": "text"
      },
      "source": [
        "generator function for 'windowing' data.  \n",
        "returns indices of start and end of each window, size of parameter 'window_size'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3hYEJ4-dxrK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_features(parent_dir,sub_dirs,file_ext=\"*.wav\",bands = 20, frames = 41):\n",
        "    window_size = 512 * (frames - 1)\n",
        "    mfccs = []\n",
        "    labels = []\n",
        "    for l, sub_dir in enumerate(sub_dirs):\n",
        "        for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
        "            sound_clip,s = librosa.load(fn)\n",
        "            #UrbanSound8K/audio/fold*/*.wav\n",
        "            label = fn.split('/')[-1].split('-')[1]\n",
        "            for (start,end) in windows(sound_clip,window_size):\n",
        "              if len(sound_clip[start:end]) == window_size:\n",
        "                signal = sound_clip[start:end]\n",
        "                mfcc = librosa.feature.mfcc(y=signal, sr=s, n_mfcc = bands).T.flatten()[:, np.newaxis].T\n",
        "                mfccs.append(mfcc)\n",
        "                labels.append(label)         \n",
        "    features = np.asarray(mfccs).reshape(len(mfccs),frames,bands)\n",
        "    return np.array(features), np.array(labels,dtype = np.int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwWNOAJlfMPk",
        "colab_type": "text"
      },
      "source": [
        "Read and pre-process all data in each 'fold_'.  \n",
        "Open and process each wav data with librosa.mfcc module and return list of data and labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Obk0W3edzD0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot_encode(labels):\n",
        "    n_labels = len(labels)\n",
        "    n_unique_labels = len(np.unique(labels))\n",
        "    one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
        "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
        "    return one_hot_encode"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBOmTwTFgzZY",
        "colab_type": "text"
      },
      "source": [
        "One hot encoding function. labels returned from extract_features function is like  \n",
        "[1,3,2,...].  \n",
        "We have to convert this labels to form of one hot encode data like  \n",
        "[[0,1,0,0,0,0,...]   \n",
        " [0,0,0,1,0,0,...]  \n",
        " [0,0,1,0,0,0,...]...]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qyyn7dqvhtsQ",
        "colab_type": "text"
      },
      "source": [
        "Now, let's load data!  \n",
        "We will use data in fold0-6 to train.  \n",
        "Use data in fold7-9 to validate.  \n",
        "Use data in fold10 to test model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVjqM9YRxXfK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parent_dir = 'UrbanSound8K/audio'\n",
        "tr_features = []\n",
        "tr_labels = []\n",
        "ts_features = []\n",
        "ts_labels = []\n",
        "\n",
        "for i in range(0,7) :\n",
        "  sub_dirs = ['fold{}'.format(i)]\n",
        "  print('start loading 'sub_dirs)\n",
        "  tmp_features,tmp_labels = extract_features(parent_dir,sub_dirs)\n",
        "  tmp_labels = one_hot_encode(tmp_labels)\n",
        "  tr_features.extend(tmp_features)\n",
        "  tr_labels.extend(tmp_labels)\n",
        "  print('load complete')\n",
        "\n",
        "for i in range(7,10) :\n",
        "  sub_dirs = ['fold{}'.format(i)]\n",
        "  print('start loading 'sub_dirs)\n",
        "  tmp_features,tmp_labels = extract_features(parent_dir,sub_dirs)\n",
        "  tmp_labels = one_hot_encode(tmp_labels)\n",
        "  ts_features.extend(tmp_features)\n",
        "  ts_labels.extend(tmp_labels)\n",
        "  print('load complete')\n",
        "\n",
        "sub_dirs = ['fold10']\n",
        "print('start loading 'sub_dirs)\n",
        "test_features, test_labels = extract_features(parent_dir,sub_dirs)\n",
        "test_labels = one_hot_encode(test_labels)\n",
        "print('load complete')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrRi4-7niVFa",
        "colab_type": "text"
      },
      "source": [
        "Keep in patience... It requires long time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_qwgEBAinx-",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "Use pickle for save and load features.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zt_uBmIqkIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "f1=open('tr.pk','wb')\n",
        "f2=open('ts.pk','wb')\n",
        "f3=open('test.pk','wb')\n",
        "tr=[[tr_features],[tr_labels]]\n",
        "ts=[[ts_features],[ts_labels]]\n",
        "test=[[test_features],[test_labels]]\n",
        "pickle.dump(tr,f1)\n",
        "pickle.dump(ts,f2)\n",
        "pickle.dump(test,f3)\n",
        "f1.close()\n",
        "f2.close()\n",
        "f3.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7D6W54Jq_rR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "f1=open('tr.pk','rb')\n",
        "f2=open('ts.pk','rb')\n",
        "f3=open('test.pk','rb')\n",
        "tr=pickle.load(f1)\n",
        "ts=pickle.load(f2)\n",
        "test=pickle.load(f3)\n",
        "tr_features=np.array(tr[0][0])\n",
        "tr_labels=np.array(tr[1][0])\n",
        "ts_features=np.array(ts[0][0])\n",
        "ts_labels=np.array(ts[1][0])\n",
        "test_features=np.array(test[0][0])\n",
        "test_labels=np.array(test[1][0])\n",
        "f1.close()\n",
        "f2.close()\n",
        "f3.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9l5w8G1kiw_X",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9-mbxaii6a3",
        "colab_type": "text"
      },
      "source": [
        "Ok, now let's check our data's shape."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_ziJ7eX7cb-",
        "colab_type": "code",
        "outputId": "4af95559-d130-4929-a6ce-bcc76da14e18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(tr_features.shape, tr_labels.shape)\n",
        "print(ts_features.shape, ts_labels.shape)\n",
        "print(test_features.shape, test_labels.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(33503, 41, 20) (33503, 10)\n",
            "(15337, 41, 20) (15337, 10)\n",
            "(5218, 41, 20) (5218, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGxXXNj9jB1k",
        "colab_type": "text"
      },
      "source": [
        "I intend to split data size of train : validate : test to 6:3:1  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHBhvhWP1tL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training Parameters\n",
        "epochs = 20\n",
        "batch_size = 50\n",
        "\n",
        "# Network Parameters\n",
        "n_input = 20\n",
        "n_steps = 41\n",
        "n_hidden = 300\n",
        "n_classes = 10\n",
        "use_dropout = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_x2qvXHjtnZ",
        "colab_type": "text"
      },
      "source": [
        "I build RNN model with 2 layers of LSTM and Dense layer is following after those layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVqmyfzKx3J5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "a8cee8da-378b-4634-cab0-83c4f437e622"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(n_hidden, input_shape=(n_steps,n_input), return_sequences=True))\n",
        "model.add(LSTM(n_hidden, input_shape=(n_steps,n_input), return_sequences=False))\n",
        "#model.add(BatchNormalization())\n",
        "if use_dropout:\n",
        "    model.add(Dropout(0.5))\n",
        "model.add(Dense(n_classes))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clWx_Jly3S1z",
        "colab_type": "code",
        "outputId": "e139572a-3e30-43b5-e433-abba9f19b984",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        }
      },
      "source": [
        "SVG(model_to_dot(model, show_shapes=True, dpi=65).create(prog='dot', format='svg'))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"349pt\" viewBox=\"0.00 0.00 332.00 387.00\" width=\"300pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(.9028 .9028) rotate(0) translate(4 383)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-383 328,-383 328,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140106809044888 -->\n<g class=\"node\" id=\"node1\">\n<title>140106809044888</title>\n<polygon fill=\"none\" points=\"0,-332.5 0,-378.5 324,-378.5 324,-332.5 0,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"82\" y=\"-351.8\">lstm_1_input: InputLayer</text>\n<polyline fill=\"none\" points=\"164,-332.5 164,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"193\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"164,-355.5 222,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"193\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"222,-332.5 222,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"273\" y=\"-363.3\">(None, 41, 20)</text>\n<polyline fill=\"none\" points=\"222,-355.5 324,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"273\" y=\"-340.3\">(None, 41, 20)</text>\n</g>\n<!-- 140106809042816 -->\n<g class=\"node\" id=\"node2\">\n<title>140106809042816</title>\n<polygon fill=\"none\" points=\"27,-249.5 27,-295.5 297,-295.5 297,-249.5 27,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"78\" y=\"-268.8\">lstm_1: LSTM</text>\n<polyline fill=\"none\" points=\"129,-249.5 129,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"158\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"129,-272.5 187,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"158\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"187,-249.5 187,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"242\" y=\"-280.3\">(None, 41, 20)</text>\n<polyline fill=\"none\" points=\"187,-272.5 297,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"242\" y=\"-257.3\">(None, 41, 300)</text>\n</g>\n<!-- 140106809044888&#45;&gt;140106809042816 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140106809044888-&gt;140106809042816</title>\n<path d=\"M162,-332.3799C162,-324.1745 162,-314.7679 162,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"165.5001,-305.784 162,-295.784 158.5001,-305.784 165.5001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140106809044216 -->\n<g class=\"node\" id=\"node3\">\n<title>140106809044216</title>\n<polygon fill=\"none\" points=\"27,-166.5 27,-212.5 297,-212.5 297,-166.5 27,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"78\" y=\"-185.8\">lstm_2: LSTM</text>\n<polyline fill=\"none\" points=\"129,-166.5 129,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"158\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"129,-189.5 187,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"158\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"187,-166.5 187,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"242\" y=\"-197.3\">(None, 41, 300)</text>\n<polyline fill=\"none\" points=\"187,-189.5 297,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"242\" y=\"-174.3\">(None, 300)</text>\n</g>\n<!-- 140106809042816&#45;&gt;140106809044216 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140106809042816-&gt;140106809044216</title>\n<path d=\"M162,-249.3799C162,-241.1745 162,-231.7679 162,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"165.5001,-222.784 162,-212.784 158.5001,-222.784 165.5001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140106809045568 -->\n<g class=\"node\" id=\"node4\">\n<title>140106809045568</title>\n<polygon fill=\"none\" points=\"36,-83.5 36,-129.5 288,-129.5 288,-83.5 36,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"89.5\" y=\"-102.8\">dense_1: Dense</text>\n<polyline fill=\"none\" points=\"143,-83.5 143,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"172\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"143,-106.5 201,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"172\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"201,-83.5 201,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244.5\" y=\"-114.3\">(None, 300)</text>\n<polyline fill=\"none\" points=\"201,-106.5 288,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244.5\" y=\"-91.3\">(None, 10)</text>\n</g>\n<!-- 140106809044216&#45;&gt;140106809045568 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140106809044216-&gt;140106809045568</title>\n<path d=\"M162,-166.3799C162,-158.1745 162,-148.7679 162,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"165.5001,-139.784 162,-129.784 158.5001,-139.784 165.5001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140106806353144 -->\n<g class=\"node\" id=\"node5\">\n<title>140106806353144</title>\n<polygon fill=\"none\" points=\"16,-.5 16,-46.5 308,-46.5 308,-.5 16,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"93\" y=\"-19.8\">activation_1: Activation</text>\n<polyline fill=\"none\" points=\"170,-.5 170,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"199\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"170,-23.5 228,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"199\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"228,-.5 228,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"268\" y=\"-31.3\">(None, 10)</text>\n<polyline fill=\"none\" points=\"228,-23.5 308,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"268\" y=\"-8.3\">(None, 10)</text>\n</g>\n<!-- 140106809045568&#45;&gt;140106806353144 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140106809045568-&gt;140106806353144</title>\n<path d=\"M162,-83.3799C162,-75.1745 162,-65.7679 162,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"165.5001,-56.784 162,-46.784 158.5001,-56.784 165.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqfP3jOQj-XW",
        "colab_type": "text"
      },
      "source": [
        "Use adam optimizer, categorical crossentropy for loss function and categorical accuracy for metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTsCBH1x3f_y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "35f5c118-9041-47e1-d126-b277838b2cae"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 41, 300)           385200    \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 300)               721200    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                3010      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,109,410\n",
            "Trainable params: 1,109,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzkdguIBFJPD",
        "colab_type": "code",
        "outputId": "cf3abaff-7bf4-4959-b90b-89f9fdeef193",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(tr_features,tr_labels,epochs=epochs,batch_size=batch_size,validation_data=(ts_features,ts_labels))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 33503 samples, validate on 15337 samples\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "33503/33503 [==============================] - 149s 4ms/step - loss: 0.7480 - categorical_accuracy: 0.7487 - val_loss: 1.9681 - val_categorical_accuracy: 0.4904\n",
            "Epoch 2/20\n",
            "33503/33503 [==============================] - 140s 4ms/step - loss: 0.4309 - categorical_accuracy: 0.8562 - val_loss: 2.2967 - val_categorical_accuracy: 0.4917\n",
            "Epoch 3/20\n",
            "33503/33503 [==============================] - 140s 4ms/step - loss: 0.3051 - categorical_accuracy: 0.8969 - val_loss: 2.1990 - val_categorical_accuracy: 0.5193\n",
            "Epoch 4/20\n",
            "33503/33503 [==============================] - 140s 4ms/step - loss: 0.2616 - categorical_accuracy: 0.9114 - val_loss: 2.3001 - val_categorical_accuracy: 0.5173\n",
            "Epoch 5/20\n",
            "33503/33503 [==============================] - 139s 4ms/step - loss: 0.2201 - categorical_accuracy: 0.9271 - val_loss: 2.3915 - val_categorical_accuracy: 0.5046\n",
            "Epoch 6/20\n",
            "33503/33503 [==============================] - 138s 4ms/step - loss: 0.1908 - categorical_accuracy: 0.9358 - val_loss: 2.5075 - val_categorical_accuracy: 0.5319\n",
            "Epoch 7/20\n",
            "33503/33503 [==============================] - 136s 4ms/step - loss: 0.1683 - categorical_accuracy: 0.9448 - val_loss: 2.3956 - val_categorical_accuracy: 0.5389\n",
            "Epoch 8/20\n",
            "33503/33503 [==============================] - 134s 4ms/step - loss: 0.1277 - categorical_accuracy: 0.9574 - val_loss: 2.5182 - val_categorical_accuracy: 0.5436\n",
            "Epoch 9/20\n",
            "33503/33503 [==============================] - 134s 4ms/step - loss: 0.1215 - categorical_accuracy: 0.9603 - val_loss: 2.4539 - val_categorical_accuracy: 0.5150\n",
            "Epoch 10/20\n",
            "33503/33503 [==============================] - 136s 4ms/step - loss: 0.1106 - categorical_accuracy: 0.9633 - val_loss: 2.6186 - val_categorical_accuracy: 0.5316\n",
            "Epoch 11/20\n",
            "33503/33503 [==============================] - 134s 4ms/step - loss: 0.1089 - categorical_accuracy: 0.9633 - val_loss: 2.6045 - val_categorical_accuracy: 0.5313\n",
            "Epoch 12/20\n",
            "33503/33503 [==============================] - 135s 4ms/step - loss: 0.0794 - categorical_accuracy: 0.9740 - val_loss: 2.9535 - val_categorical_accuracy: 0.5072\n",
            "Epoch 13/20\n",
            "33503/33503 [==============================] - 134s 4ms/step - loss: 0.0853 - categorical_accuracy: 0.9725 - val_loss: 2.9300 - val_categorical_accuracy: 0.4957\n",
            "Epoch 14/20\n",
            "33503/33503 [==============================] - 135s 4ms/step - loss: 0.0608 - categorical_accuracy: 0.9805 - val_loss: 2.8794 - val_categorical_accuracy: 0.5338\n",
            "Epoch 15/20\n",
            "33503/33503 [==============================] - 134s 4ms/step - loss: 0.0896 - categorical_accuracy: 0.9711 - val_loss: 2.4961 - val_categorical_accuracy: 0.5215\n",
            "Epoch 16/20\n",
            "33503/33503 [==============================] - 134s 4ms/step - loss: 0.0660 - categorical_accuracy: 0.9784 - val_loss: 2.7460 - val_categorical_accuracy: 0.5259\n",
            "Epoch 17/20\n",
            "33503/33503 [==============================] - 134s 4ms/step - loss: 0.0529 - categorical_accuracy: 0.9837 - val_loss: 2.9638 - val_categorical_accuracy: 0.5305\n",
            "Epoch 18/20\n",
            "33503/33503 [==============================] - 135s 4ms/step - loss: 0.0537 - categorical_accuracy: 0.9834 - val_loss: 2.8769 - val_categorical_accuracy: 0.5292\n",
            "Epoch 19/20\n",
            "33503/33503 [==============================] - 135s 4ms/step - loss: 0.0603 - categorical_accuracy: 0.9799 - val_loss: 2.9959 - val_categorical_accuracy: 0.5429\n",
            "Epoch 20/20\n",
            "33503/33503 [==============================] - 133s 4ms/step - loss: 0.0454 - categorical_accuracy: 0.9846 - val_loss: 3.1148 - val_categorical_accuracy: 0.5309\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6d20aaccf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rhxYH5GkPeZ",
        "colab_type": "text"
      },
      "source": [
        "Training time is average 135 seconds per epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0varvOLPepP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "69bce00e-2be0-4a63-cf45-813c8c578cc0"
      },
      "source": [
        "# Evaluating the model on the training and testing set\n",
        "score = model.evaluate(tr_features, tr_labels, verbose=0)\n",
        "print(\"Training Accuracy: \", score[1])\n",
        "\n",
        "score = model.evaluate(test_features, test_labels, verbose=0)\n",
        "print(\"Testing Accuracy: \", score[1])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy:  0.9898815031489717\n",
            "Testing Accuracy:  0.504024530471445\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rR5hTGgckhVh",
        "colab_type": "text"
      },
      "source": [
        "Training accuracy is 0.98 and it is very high.  \n",
        "But testing accuracy is 0.5  \n",
        "Somewhy, model is overfitted to training data.  \n",
        "Maybe applying regularization and normalization methods can solve this problem."
      ]
    }
  ]
}